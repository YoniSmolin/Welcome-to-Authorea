<h1 id="auto-label-section-812642" class="ltx_title_section">Abstract<br></h1><div>As RGB-D sensors like Kinect become cheaper and more popular, it is interesting to look into the benefits of constructing arrays of such sensors. This report deals with the technical aspect of assembling a sensor network. Each node int the network is comprised of an RGB-D sensor and is powered with a local processing unit. All the nodes are synchronized to a single central processing unit. Thus, the network can perform both distributed and centralized processing. Such a network can be used as an efficient platform for various kinds of computer vision applications, including room mapping, event detection and tracking.<br></div><h1 id="auto-label-section-451451" class="ltx_title_section">Introduction<br></h1><div>The concrete system discussed in this report is comprised of a set of <a href="http://www.microsoft.com/en-us/kinectforwindows/purchase/" target="_blank">Microsoft Kinect v2</a>&nbsp;sensors, each paired with a single <a href="http://www.nvidia.com/object/jetson-tk1-embedded-dev-kit.html" target="_blank">Nvidia Jetston TK1</a> developer board. Each Kinect is connected to its corresponding Jetson board via USB3.0. The boards are all connected to the local network via ethernet and can be controlled by any computer which is also connected to this network. An illustration of the system, for the case of 4 sensors, is shown in figure 1.<br></div><div><br></div><div>The purpose of this report is to describe the architecture of the assembled system and investigate its performance and scalability potential.<br></div><div>&nbsp;<br></div><div>In order for it to serve as a platform for various computer vision and 3D imaging applications, the discussed system must satisfy the following minimal requirements:<br></div><ul><li><div>Reliable networking between the Jetson boards and the controlling computer must be established.<br></div></li><li><div>The incoming data streams from different sensors must be synchronized to allow for their consistent aggregation.<br></div></li><li><div>A simple and robust calibration method of the depth sensors' reference frames is required.<br></div></li></ul><h1 id="auto-label-section-864479" class="ltx_title_section">Experimental Details<br></h1><div><br></div><h1 id="auto-label-section-592286" class="ltx_title_section">Results and Discussions<br></h1><div><br></div><h1 id="auto-label-section-691549" class="ltx_title_section">Conclusions and Recommendations<br></h1><div><br></div><h1 id="auto-label-section-539285" class="ltx_title_section">References<br></h1><div><br></div>